name: llm-topology
services:
  vllm:
    image: vllm/vllm-openai:latest
    command: >
      --host 0.0.0.0
      --port 8000
      --model ${MODEL_NAME}
      --dtype auto
      --max-model-len ${VLLM_MAX_CONTEXT_LEN:-8192}
      --trust-remote-code
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN:-}
    volumes:
      - ${MODEL_DIR:-./models}:/models:ro
    ports:
      - "8000:8000"
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    gpus: all
    healthcheck:
      test: ["CMD", "bash", "-lc", "curl -sf http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 3s
      retries: 10

  postgres:
    image: postgres:16
    environment:
      - POSTGRES_DB=topology
      - POSTGRES_USER=topo
      - POSTGRES_PASSWORD=topo
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U topo -d topology"]
      interval: 10s
      timeout: 3s
      retries: 10

  state-server:
    build:
      context: ./services/state-server
      dockerfile: Dockerfile
    environment:
      - DB_URL=postgresql://topo:topo@postgres:5432/topology
      - API_PORT=8080
      - UI_WS_ORIGIN=${UI_WS_ORIGIN:-*}
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "8080:8080"

  analyst:
    build:
      context: ./services/llm-analyst
      dockerfile: Dockerfile
    environment:
      - LLM_BASE_URL=http://vllm:8000/v1
      - LLM_MODEL=${MODEL_NAME}
      - RESPONSE_FORMAT=${RESPONSE_FORMAT:-json_schema}
      - JSON_SCHEMA_PATH=/app/schemas/topology_patch.schema.json
      - SYSTEM_PROMPT_PATH=/app/prompts/system_topologist.txt
      - BATCH_MS=${BATCH_MS:-250}
      - MAX_EVIDENCE_ITEMS=${MAX_EVIDENCE_ITEMS:-512}
      - STATE_SERVER_URL=http://state-server:8080
      - SEED_GATEWAY_IP=${GATEWAY_IP:-}
      - SEED_FIREWALL_IP=${FIREWALL_IP:-}
    volumes:
      - ./schemas:/app/schemas:ro
      - ./prompts:/app/prompts:ro
    ports:
      - "8100:8100"
    depends_on:
      vllm:
        condition: service_started
      state-server:
        condition: service_started

  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    environment:
      - VITE_API_BASE=http://${SERVER_IP}:8080
      - VITE_WS_BASE=ws://${SERVER_IP}:8080
    volumes:
      - ./ui/src:/app/src
      - ./ui/index.html:/app/index.html
    ports:
      - "3000:3000"
    depends_on:
      state-server:
        condition: service_started

  packet-collector:
    build:
      context: ./services/packet-collector
      dockerfile: Dockerfile
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
    environment:
      - IFACE=${PCAP_IFACE:-eth0}
      - BATCH_MS=${BATCH_MS:-250}
      - MAX_EVIDENCE_ITEMS=${MAX_EVIDENCE_ITEMS:-1024}
      - FILTER_BPF=${FILTER_BPF:-arp or ip or ip6}
      - ANALYST_URL=${ANALYST_URL:-http://127.0.0.1:8100/tick}
      - STATE_SERVER_URL=${STATE_SERVER_URL:-http://127.0.0.1:8080}
      - SEED_GATEWAY_IP=${GATEWAY_IP:-}
      - SEED_FIREWALL_IP=${FIREWALL_IP:-}
      - HEALTH_PORT=9100
      - TZ=UTC
    volumes:
      - packet_data:/data
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://127.0.0.1:9100/health"]
      interval: 10s
      timeout: 3s
      retries: 10
    restart: unless-stopped
    depends_on:
      state-server:
        condition: service_started

  port-scanner:
    build:
      context: ./services/port-scanner
      dockerfile: Dockerfile
    environment:
      - STATE_SERVER_URL=http://state-server:8080
      - SCAN_INTERVAL_SECONDS=${SCAN_INTERVAL_SECONDS:-300}
      - SCAN_PORTS=${SCAN_PORTS:-22,23,80,443,554,1883,5060,8080,8443,161,179,3389}
      - CONNECTION_TIMEOUT=${CONNECTION_TIMEOUT:-2.0}
      - HEALTH_PORT=9200
    ports:
      - "9200:9200"
    depends_on:
      state-server:
        condition: service_started
    restart: unless-stopped

  snmp-discovery:
    build:
      context: ./services/snmp-discovery
      dockerfile: Dockerfile
    environment:
      - STATE_SERVER_URL=http://state-server:8080
      - SCAN_INTERVAL_SECONDS=${SNMP_SCAN_INTERVAL_SECONDS:-300}
      - SNMP_COMMUNITY=${SNMP_COMMUNITY:-public}
      - SNMP_TIMEOUT=${SNMP_TIMEOUT:-2.0}
      - SNMP_RETRIES=${SNMP_RETRIES:-1}
      - HEALTH_PORT=9300
    ports:
      - "9300:9300"
    depends_on:
      state-server:
        condition: service_started
    restart: unless-stopped

  mac-enricher:
    build:
      context: ./services/mac-enricher
      dockerfile: Dockerfile
    environment:
      - STATE_SERVER_URL=http://state-server:8080
      - SCAN_INTERVAL_SECONDS=${MAC_SCAN_INTERVAL_SECONDS:-3600}
      - HEALTH_PORT=9400
    ports:
      - "9400:9400"
    volumes:
      - mac_oui_data:/data
    depends_on:
      state-server:
        condition: service_started
    restart: unless-stopped

  mib-assigner:
    build:
      context: ./services/mib-assigner
      dockerfile: Dockerfile
    environment:
      - STATE_SERVER_URL=http://state-server:8080
      - SCAN_INTERVAL_SECONDS=${MIB_ASSIGN_INTERVAL_SECONDS:-600}
      - HEALTH_PORT=9500
    ports:
      - "9500:9500"
    depends_on:
      state-server:
        condition: service_started
    restart: unless-stopped

  mib-walker:
    build:
      context: ./services/mib-walker
      dockerfile: Dockerfile
    environment:
      - STATE_SERVER_URL=http://state-server:8080
      - WALK_INTERVAL_SECONDS=${MIB_WALK_INTERVAL_SECONDS:-1800}
      - HEALTH_PORT=9600
    ports:
      - "9600:9600"
    depends_on:
      state-server:
        condition: service_started
    restart: unless-stopped

volumes:
  pgdata:
  packet_data:
  mac_oui_data:
